{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/icb/dominik.klein/mambaforge/envs/entot_pip/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/icb/dominik.klein/mambaforge/envs/entot_pip/lib/python3.11/site-packages/equinox/_ad.py:753: UserWarning: As of Equinox 0.10.7, `equinox.filter_custom_vjp.defvjp` is deprecated in favour of `.def_fwd` and `.def_bwd`. This new API supports symbolic zeros, which allow for more efficient autodifferentiation rules. In particular:\n",
      "- the fwd and bwd functions take an extra `perturbed` argument, which     indicates which primals actually need a gradient. You can use this     to skip computing the gradient for any unperturbed value. (You can     also safely just ignore this if you wish.)\n",
      "- `None` was previously passed to indicate a symbolic zero gradient for     all objects that weren't inexact arrays, but all inexact arrays     always had an array-valued gradient. Now, `None` may also be passed     to indicate that an inexact array has a symbolic zero gradient.\n",
      "  warnings.warn(\n",
      "2024-05-07 09:20:58.328175: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import scanpy as sc\n",
    "import optax\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing as pp\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "import ott\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from ott.geometry import geometry, pointcloud\n",
    "import jax\n",
    "from typing import Mapping, Any, Optional, Union, Callable, Tuple\n",
    "from types import MappingProxyType\n",
    "import jax.numpy as jnp\n",
    "from functools import partial\n",
    "from ott.solvers.linear import sinkhorn\n",
    "from ott.problems.linear import linear_problem\n",
    "from entot.models.model import OTFlowMatching\n",
    "from entot.nets.nets import MLP_vector_field, MLP_bridge, MLP_marginal,MLP_fused_vector_field\n",
    "import sklearn.preprocessing as pp\n",
    "import scanpy as sc\n",
    "from ott.solvers.linear import sinkhorn, acceleration\n",
    "from sklearn import preprocessing as pp\n",
    "\n",
    "\n",
    "from ott.geometry.pointcloud import PointCloud\n",
    "from ott.tools.sinkhorn_divergence import sinkhorn_divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foscttm(\n",
    "    x: np.ndarray,\n",
    "    y: np.ndarray,\n",
    ") -> float:\n",
    "    d = scipy.spatial.distance_matrix(x, y)\n",
    "    foscttm_x = (d < np.expand_dims(np.diag(d), axis=1)).mean(axis=1)\n",
    "    foscttm_y = (d < np.expand_dims(np.diag(d), axis=0)).mean(axis=0)\n",
    "    fracs = []\n",
    "    for i in range(len(foscttm_x)):\n",
    "        fracs.append((foscttm_x[i] + foscttm_y[i]) / 2)\n",
    "    return np.mean(fracs).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_atac = sc.read(\"../../data/bone_marrow_atac.h5ad\")\n",
    "adata_rna = sc.read(\"../../data/bone_marrow_rna.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_source=adata_atac.copy()\n",
    "adata_target=adata_rna.copy()\n",
    "\n",
    "n_cells_source=len(adata_atac)\n",
    "\n",
    "n_samples_train = int(n_cells_source * 0.6)\n",
    "n_samples_test = n_cells_source - n_cells_source\n",
    "\n",
    "inds_train = np.asarray(jax.random.choice(jax.random.PRNGKey(0), n_cells_source, (n_samples_train,), replace=False))\n",
    "inds_test = list(set(list(range(n_cells_source))) - set(np.asarray(inds_train)))\n",
    "\n",
    "fused = np.concatenate((adata_atac.obsm[\"geneactivity_scvi\"], adata_rna.obsm[\"geneactivity_scvi\"]), axis=0)\n",
    "fused = sc.pp.pca(fused, n_comps=25)\n",
    "\n",
    "source_fused = fused[:len(adata_source), :]\n",
    "target_fused = fused[len(adata_target):, :]\n",
    "\n",
    "source_q = pp.normalize(\n",
    "    adata_source.obsm[\"ATAC_lsi_red\"], norm=\"l2\"\n",
    ") \n",
    "target_q = adata_target.obsm[\"GEX_X_pca\"]\n",
    "\n",
    "source_train_q = source_q[inds_train, :]\n",
    "source_test_q = source_q[inds_test, :]\n",
    "target_train_q = target_q[inds_train, :]\n",
    "target_test_q = target_q[inds_test, :]\n",
    "source_train_fused = source_fused[inds_train, :]\n",
    "source_test_fused = source_fused[inds_test, :]\n",
    "target_train_fused = target_fused[inds_train, :]\n",
    "target_test_fused = target_fused[inds_test, :]\n",
    "\n",
    "source_train = np.concatenate((source_train_fused, source_train_q), axis=1)\n",
    "source_test = np.concatenate((source_test_fused, source_test_q), axis=1)\n",
    "target_train = np.concatenate((target_train_fused, target_train_q), axis=1)\n",
    "target_test = np.concatenate((target_test_fused, target_test_q), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024]\n",
    "tot_samples_seen = 5_000 * 1024\n",
    "foscttms_one_sample = [None] * len(batch_sizes)\n",
    "foscttms_cond_mean = [None] * len(batch_sizes)\n",
    "sinkhorn_divs_one_sample = [None] * len(batch_sizes)\n",
    "sinkhorn_divs_cond_mean = [None] * len(batch_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_net = MLP_vector_field(target_train.shape[1], latent_embed_dim = 256, num_layers=8, n_frequencies=128)\n",
    "bridge_net = MLP_bridge(target_train.shape[1], 10)\n",
    "linear_ot_solver = sinkhorn.Sinkhorn(\n",
    "                momentum=acceleration.Momentum(value=1., start=25)\n",
    "        )\n",
    "solver = ott.solvers.quadratic.gromov_wasserstein.GromovWasserstein(epsilon=0.01, linear_ot_solver=linear_ot_solver)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = [1024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_test = [None] * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [06:24<00:00, 13.02it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m res_test \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m----> 7\u001b[0m     \u001b[43mres_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m otfm\u001b[38;5;241m.\u001b[39mtransport(source_test, seed\u001b[38;5;241m=\u001b[39mi)[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\n\u001b[1;32m      8\u001b[0m cond_mean_test \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mmean(jnp\u001b[38;5;241m.\u001b[39masarray(res_test), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      9\u001b[0m one_sample_test \u001b[38;5;241m=\u001b[39m res_test[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    }
   ],
   "source": [
    "for j, bs in enumerate(batch_sizes):\n",
    "    num_iter = min(tot_samples_seen // bs, 100_000)\n",
    "    otfm = OTFlowMatching(neural_net, bridge_net, epsilon=None, scale_cost=\"mean\", input_dim=source_train.shape[1], output_dim=target_train.shape[1], iterations=num_iter, ot_solver=solver, k_noise_per_x=1, fused_penalty = 1.0, split_dim=fused.shape[1])\n",
    "    otfm(source_train, target_train, bs, bs)\n",
    "    res_test = [None] * 1\n",
    "    for i in range(5):\n",
    "        res_test[i] = otfm.transport(source_test, seed=i)[0][0,...]\n",
    "    cond_mean_test = jnp.mean(jnp.asarray(res_test), axis=0)\n",
    "    one_sample_test = res_test[0]\n",
    "    foscttms_one_sample[j] = foscttm(one_sample_test, target_test)\n",
    "    foscttms_cond_mean[j] = foscttm(cond_mean_test, target_test)\n",
    "    sinkhorn_divs_one_sample[j] = float(sinkhorn_divergence(PointCloud, one_sample_test, target_test, epsilon=1e-2).divergence)\n",
    "    sinkhorn_divs_cond_mean[j] = float(sinkhorn_divergence(PointCloud, cond_mean_test, target_test, epsilon=1e-2).divergence)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foscttms_one_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_mean_test = jnp.mean(jnp.asarray(res_test), axis=0)\n",
    "one_sample_test = res_test[0]\n",
    "foscttms_one_sample[j] = foscttm(one_sample_test, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1116, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foscttms_one_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "entot_pip",
   "language": "python",
   "name": "entot_pip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
