{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/icb/dominik.klein/mambaforge/envs/entot_pip/lib/python3.11/site-packages/equinox/_ad.py:753: UserWarning: As of Equinox 0.10.7, `equinox.filter_custom_vjp.defvjp` is deprecated in favour of `.def_fwd` and `.def_bwd`. This new API supports symbolic zeros, which allow for more efficient autodifferentiation rules. In particular:\n",
      "- the fwd and bwd functions take an extra `perturbed` argument, which     indicates which primals actually need a gradient. You can use this     to skip computing the gradient for any unperturbed value. (You can     also safely just ignore this if you wish.)\n",
      "- `None` was previously passed to indicate a symbolic zero gradient for     all objects that weren't inexact arrays, but all inexact arrays     always had an array-valued gradient. Now, `None` may also be passed     to indicate that an inexact array has a symbolic zero gradient.\n",
      "  warnings.warn(\n",
      "2023-08-11 17:56:07.720547: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/icb/dominik.klein/mambaforge/envs/entot_pip/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import jax\n",
    "import ott\n",
    "import diffrax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from entot.data.data import MixtureNormalSampler\n",
    "from entot.models.model import OTFlowMatching\n",
    "from entot.nets.nets import MLP_vector_field, Bridge_MLP_mean, MLP_marginal\n",
    "from entot.plotting.plots import plot_1D_unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-11 17:56:12.235295: W external/xla/xla/service/gpu/nvptx_compiler.cc:698] The NVIDIA driver's CUDA version is 12.1 which is older than the ptxas CUDA version (12.2.128). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    }
   ],
   "source": [
    "source = MixtureNormalSampler(jax.random.PRNGKey(0), [0], 1,  0.5, batch_size=1024)\n",
    "target = MixtureNormalSampler(jax.random.PRNGKey(1), [-1.0,1.0, 5.0], 1,  0.1, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1e-1\n",
    "tau_a = 0.98\n",
    "tau_b = 0.98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_net = MLP_vector_field(1, 128, 128, 128, n_frequencies=10)\n",
    "bridge_net = Bridge_MLP_mean(1, 64, 64)\n",
    "ot_solver = ott.solvers.linear.sinkhorn.Sinkhorn()\n",
    "solver_latent_to_data = ott.solvers.linear.sinkhorn.Sinkhorn()\n",
    "\n",
    "mlp_eta = MLP_marginal(1, 128)\n",
    "mlp_xi = MLP_marginal(1, 128)\n",
    "\n",
    "otfm = OTFlowMatching(neural_net, bridge_net=bridge_net, ot_solver=ot_solver, epsilon=epsilon, mlp_eta=mlp_eta, mlp_xi=mlp_xi, tau_a=tau_a, tau_b=tau_b, input_dim=1, output_dim=1, iterations=20_000, k_noise_per_x=10, solver_latent_to_data=solver_latent_to_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a shape 0 is 1024 \n",
      "(1024,)\n",
      "sum of k samples per x 10\n",
      "shape of k samples per x (1024,)\n",
      "shape of tmat augmented (10240, 1024)\n",
      "shape of a argument (1024,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:10<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target batch shape (10240, 1, 1)\n",
      "source batch shape (10240, 1)\n",
      "noise batch shape (1024, 10, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "vmap got inconsistent sizes for array axes to be mapped:\n  * most axes (2 of them) had size 10240, e.g. axis 0 of argument key of type uint32[10240,2];\n  * one axis had size 1024: axis 0 of argument x of type float32[1024,10,1]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m otfm\u001b[38;5;241m.\u001b[39miterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2_000\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43motfm\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git_repos/entot/entot/models/model.py:279\u001b[0m, in \u001b[0;36mOTFlowMatching.__call__\u001b[0;34m(self, x, y, batch_size_source, batch_size_target)\u001b[0m\n\u001b[1;32m    269\u001b[0m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m t[:, \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m    270\u001b[0m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnoise\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnoise_fn(rng_noise, shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mlen\u001b[39m(source_batch), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_noise_per_x))\n\u001b[1;32m    271\u001b[0m (\n\u001b[1;32m    272\u001b[0m     metrics,\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate_neural_net,\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate_bridge_net,\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate_eta,\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate_xi,\n\u001b[1;32m    277\u001b[0m     eta_predictions,\n\u001b[1;32m    278\u001b[0m     xi_predictions,\n\u001b[0;32m--> 279\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrng_step_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_neural_net\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_bridge_net\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_eta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_xi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m metrics\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics[key]\u001b[38;5;241m.\u001b[39mappend(value)\n",
      "File \u001b[0;32m~/git_repos/entot/entot/models/model.py:593\u001b[0m, in \u001b[0;36mOTFlowMatching._get_step_fn.<locals>.step_fn\u001b[0;34m(key, state_neural_net, state_bridge_net, batch, state_eta, state_xi)\u001b[0m\n\u001b[1;32m    591\u001b[0m jax\u001b[38;5;241m.\u001b[39mdebug\u001b[38;5;241m.\u001b[39mprint(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource batch shape \u001b[39m\u001b[38;5;132;01m{x}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, x\u001b[38;5;241m=\u001b[39msource_batch\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    592\u001b[0m jax\u001b[38;5;241m.\u001b[39mdebug\u001b[38;5;241m.\u001b[39mprint(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnoise batch shape \u001b[39m\u001b[38;5;132;01m{x}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, x\u001b[38;5;241m=\u001b[39mbatch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnoise\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m--> 593\u001b[0m noise_matched, conditional_target \u001b[38;5;241m=\u001b[39m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatch_latent_to_data_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrng_noise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnoise\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_batch\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    597\u001b[0m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mreshape(source_batch, (\u001b[38;5;28mlen\u001b[39m(source_batch), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    598\u001b[0m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mreshape(conditional_target, (\u001b[38;5;28mlen\u001b[39m(source_batch), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "File \u001b[0;32m~/mambaforge/envs/entot_pip/lib/python3.11/site-packages/jax/_src/api.py:1340\u001b[0m, in \u001b[0;36m_mapped_axis_size\u001b[0;34m(fn, tree, vals, dims, name)\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1339\u001b[0m     msg\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  * some axes (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mct\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of them) had size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msz\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, e.g. axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00max\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m;\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1340\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(msg)[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m])\n",
      "\u001b[0;31mValueError\u001b[0m: vmap got inconsistent sizes for array axes to be mapped:\n  * most axes (2 of them) had size 10240, e.g. axis 0 of argument key of type uint32[10240,2];\n  * one axis had size 1024: axis 0 of argument x of type float32[1024,10,1]"
     ]
    }
   ],
   "source": [
    "otfm.iterations=2_000\n",
    "otfm(source, target, 1024, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source.batch_size = 1024\n",
    "source_batch = next(source)\n",
    "res, _ , _= otfm.transport(source_batch, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(res[0,...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {}\n",
    "a = (-2.5, 2.5)\n",
    "b = (0.0, 2.0)\n",
    "c = (0.0, 4.0)\n",
    "d = (-2.5, 7.0)\n",
    "kwargs[\"00_xlim\"] = a\n",
    "kwargs[\"01_xlim\"] = a\n",
    "kwargs[\"02_xlim\"] = a\n",
    "kwargs[\"03_xlim\"] = b\n",
    "kwargs[\"04_xlim\"] = b\n",
    "kwargs[\"10_xlim\"] = a\n",
    "kwargs[\"11_xlim\"] = a\n",
    "kwargs[\"12_xlim\"] = b\n",
    "kwargs[\"13_xlim\"] = b\n",
    "kwargs[\"14_xlim\"] = b\n",
    "\n",
    "kwargs[\"00_ylim\"] = b\n",
    "kwargs[\"01_ylim\"] = b\n",
    "kwargs[\"02_ylim\"] = b\n",
    "kwargs[\"03_ylim\"] = d\n",
    "kwargs[\"04_ylim\"] = d\n",
    "kwargs[\"10_ylim\"] = d\n",
    "kwargs[\"11_ylim\"] = d\n",
    "kwargs[\"12_ylim\"] = d\n",
    "kwargs[\"13_ylim\"] = d\n",
    "kwargs[\"14_ylim\"] = d\n",
    "\n",
    "source.batch_size = 1024\n",
    "source_batch = next(source)\n",
    "\n",
    "target.batch_size = 1024\n",
    "target_batch = next(target)\n",
    "\n",
    "rescale_source = otfm.state_eta.apply_fn({\"params\": otfm.state_eta.params}, source_batch)\n",
    "rescale_target = otfm.state_xi.apply_fn({\"params\": otfm.state_xi.params}, target_batch)\n",
    "\n",
    "res, _, _ = otfm.transport(source_batch, seed=1, diffeqsolve_kwargs={\"max_steps\": 1_000_000})\n",
    "\n",
    "_  = plot_1D_unbalanced(source_batch, target_batch, res[0,...], rescale_source, rescale_target, epsilon=epsilon, tau_a=tau_a, tau_b=tau_b, seed=1, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def sample_conditional_indices_from_tmap(\n",
    "    key: jax.random.PRNGKeyArray, tmat: jnp.ndarray, k_samples_per_x: Optional[int]\n",
    ") -> Tuple[jnp.array, jnp.array]:\n",
    "    indices_per_row = jax.vmap(\n",
    "        lambda tmat: jax.random.choice(key=key, a=jnp.arange(len(tmat)), p=tmat, shape=(k_samples_per_x,)),\n",
    "        in_axes=0,\n",
    "        out_axes=0,\n",
    "    )(tmat)\n",
    "    return jnp.repeat(jnp.arange(tmat.shape[0]), k_samples_per_x), indices_per_row % tmat.shape[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "entot_pip",
   "language": "python",
   "name": "entot_pip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "efbfc283161dfbfd9e57c7c1b0f5809f4f3dae760ed28baec628251604b9031c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
