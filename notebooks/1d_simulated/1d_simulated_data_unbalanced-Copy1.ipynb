{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/icb/dominik.klein/mambaforge/envs/entot_pip/lib/python3.11/site-packages/equinox/_ad.py:753: UserWarning: As of Equinox 0.10.7, `equinox.filter_custom_vjp.defvjp` is deprecated in favour of `.def_fwd` and `.def_bwd`. This new API supports symbolic zeros, which allow for more efficient autodifferentiation rules. In particular:\n",
      "- the fwd and bwd functions take an extra `perturbed` argument, which     indicates which primals actually need a gradient. You can use this     to skip computing the gradient for any unperturbed value. (You can     also safely just ignore this if you wish.)\n",
      "- `None` was previously passed to indicate a symbolic zero gradient for     all objects that weren't inexact arrays, but all inexact arrays     always had an array-valued gradient. Now, `None` may also be passed     to indicate that an inexact array has a symbolic zero gradient.\n",
      "  warnings.warn(\n",
      "2023-08-28 10:38:54.646857: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/icb/dominik.klein/mambaforge/envs/entot_pip/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import jax\n",
    "import ott\n",
    "import diffrax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from entot.data.data import MixtureNormalSampler\n",
    "from entot.models.model import OTFlowMatching\n",
    "from entot.nets.nets import MLP_vector_field, Bridge_MLP_mean, MLP_marginal\n",
    "from entot.plotting.plots import plot_1D_unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-28 10:39:06.971224: W external/xla/xla/service/gpu/nvptx_compiler.cc:698] The NVIDIA driver's CUDA version is 12.1 which is older than the ptxas CUDA version (12.2.128). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    }
   ],
   "source": [
    "source = MixtureNormalSampler(jax.random.PRNGKey(0), [0], 1,  0.5, batch_size=1024)\n",
    "target = MixtureNormalSampler(jax.random.PRNGKey(1), [-1.0,1.0, 5.0], 1,  0.1, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1e-1\n",
    "tau_a = 0.98\n",
    "tau_b = 0.98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_net = MLP_vector_field(1, 128, 128, 128, n_frequencies=10)\n",
    "bridge_net = Bridge_MLP_mean(1, 64, 64)\n",
    "ot_solver = ott.solvers.linear.sinkhorn.Sinkhorn()\n",
    "solver_latent_to_data = ott.solvers.linear.sinkhorn.Sinkhorn()\n",
    "\n",
    "mlp_eta = MLP_marginal(1, 128)\n",
    "mlp_xi = MLP_marginal(1, 128)\n",
    "\n",
    "otfm = OTFlowMatching(neural_net, bridge_net=bridge_net, ot_solver=ot_solver, epsilon=epsilon, mlp_eta=mlp_eta, mlp_xi=mlp_xi, tau_a=tau_a, tau_b=tau_b, input_dim=1, output_dim=1, iterations=20_000, k_noise_per_x=10, solver_latent_to_data=solver_latent_to_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 1495/2000 [40:51<13:23,  1.59s/it] "
     ]
    }
   ],
   "source": [
    "otfm.iterations=2_000\n",
    "otfm(source, target, 1024, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source.batch_size = 1024\n",
    "source_batch = next(source)\n",
    "res, _ , _= otfm.transport(source_batch, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(res[0,...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {}\n",
    "a = (-2.5, 2.5)\n",
    "b = (0.0, 2.0)\n",
    "c = (0.0, 4.0)\n",
    "d = (-2.5, 7.0)\n",
    "kwargs[\"00_xlim\"] = a\n",
    "kwargs[\"01_xlim\"] = a\n",
    "kwargs[\"02_xlim\"] = a\n",
    "kwargs[\"03_xlim\"] = b\n",
    "kwargs[\"04_xlim\"] = b\n",
    "kwargs[\"10_xlim\"] = a\n",
    "kwargs[\"11_xlim\"] = a\n",
    "kwargs[\"12_xlim\"] = b\n",
    "kwargs[\"13_xlim\"] = b\n",
    "kwargs[\"14_xlim\"] = b\n",
    "\n",
    "kwargs[\"00_ylim\"] = b\n",
    "kwargs[\"01_ylim\"] = b\n",
    "kwargs[\"02_ylim\"] = b\n",
    "kwargs[\"03_ylim\"] = d\n",
    "kwargs[\"04_ylim\"] = d\n",
    "kwargs[\"10_ylim\"] = d\n",
    "kwargs[\"11_ylim\"] = d\n",
    "kwargs[\"12_ylim\"] = d\n",
    "kwargs[\"13_ylim\"] = d\n",
    "kwargs[\"14_ylim\"] = d\n",
    "\n",
    "source.batch_size = 1024\n",
    "source_batch = next(source)\n",
    "\n",
    "target.batch_size = 1024\n",
    "target_batch = next(target)\n",
    "\n",
    "rescale_source = otfm.state_eta.apply_fn({\"params\": otfm.state_eta.params}, source_batch)\n",
    "rescale_target = otfm.state_xi.apply_fn({\"params\": otfm.state_xi.params}, target_batch)\n",
    "\n",
    "res, _, _ = otfm.transport(source_batch, seed=1, diffeqsolve_kwargs={\"max_steps\": 1_000_000})\n",
    "\n",
    "_  = plot_1D_unbalanced(source_batch, target_batch, res[0,...], rescale_source, rescale_target, epsilon=epsilon, tau_a=tau_a, tau_b=tau_b, seed=1, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def sample_conditional_indices_from_tmap(\n",
    "    key: jax.random.PRNGKeyArray, tmat: jnp.ndarray, k_samples_per_x: Optional[int]\n",
    ") -> Tuple[jnp.array, jnp.array]:\n",
    "    indices_per_row = jax.vmap(\n",
    "        lambda tmat: jax.random.choice(key=key, a=jnp.arange(len(tmat)), p=tmat, shape=(k_samples_per_x,)),\n",
    "        in_axes=0,\n",
    "        out_axes=0,\n",
    "    )(tmat)\n",
    "    return jnp.repeat(jnp.arange(tmat.shape[0]), k_samples_per_x), indices_per_row % tmat.shape[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "entot_pip",
   "language": "python",
   "name": "entot_pip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "efbfc283161dfbfd9e57c7c1b0f5809f4f3dae760ed28baec628251604b9031c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
