{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85ca054a-bd26-4d19-8a55-32ebeb702ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"new_sc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3eb9c5c-81c7-4e53-99c7-93e3adfb30c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ott\n",
    "import jax\n",
    "from ott.problems.linear import linear_problem\n",
    "from ott.problems.quadratic import quadratic_problem\n",
    "from ott.geometry import pointcloud, geometry, costs, graph\n",
    "from ott.solvers.quadratic import gromov_wasserstein\n",
    "from typing import Optional, Any\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "from tqdm import tqdm\n",
    "from ott.neural import datasets\n",
    "from ott.neural.methods.flows import dynamics, otfm\n",
    "from ott.neural.networks.layers import time_encoder\n",
    "from ott.neural.networks.velocity_field import VelocityField\n",
    "from ott.solvers import utils as solver_utils\n",
    "from torch.utils.data import DataLoader\n",
    "import jax.numpy as jnp\n",
    "from typing import Literal, Optional\n",
    "import scanpy as sc\n",
    "import functools\n",
    "import optax\n",
    "from functools import partial\n",
    "import functools\n",
    "from typing import Any, Callable, Dict, Iterable, List, Optional, Tuple, Union\n",
    "from typing import Dict, Tuple\n",
    "from tqdm import tqdm\n",
    "import jax.tree_util as jtu\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.tree_util as jtu\n",
    "import numpy as np\n",
    "\n",
    "import diffrax\n",
    "from flax.training import train_state\n",
    "\n",
    "from ott import utils\n",
    "from ott.neural.methods.flows import dynamics\n",
    "from ott.neural.networks import velocity_field\n",
    "from ott.solvers import utils as solver_utils\n",
    "from sklearn import preprocessing as pp\n",
    "from moscot import datasets\n",
    "\n",
    "LinTerm = Tuple[jnp.ndarray, jnp.ndarray]\n",
    "QuadTerm = Tuple[jnp.ndarray, jnp.ndarray, Optional[jnp.ndarray],\n",
    "                 Optional[jnp.ndarray]]\n",
    "DataMatchFn = Union[Callable[[LinTerm], jnp.ndarray], Callable[[QuadTerm],\n",
    "                                                               jnp.ndarray]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60de845-4258-43fe-a50a-c4e3c4a41a79",
   "metadata": {},
   "source": [
    "# Fixed GENOT class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "020d1219-9ccc-4d57-bec8-b21628a82f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GENOT:\n",
    "  \"\"\"Generative Entropic Neural Optimal Transport :cite:`klein_uscidda:23`.\n",
    "\n",
    "  GENOT is a framework for learning neural optimal transport plans between\n",
    "  two distributions. It allows for learning linear and quadratic\n",
    "  (Fused) Gromov-Wasserstein couplings, in both the balanced and\n",
    "  the unbalanced setting.\n",
    "\n",
    "  Args:\n",
    "    vf: Vector field parameterized by a neural network.\n",
    "    flow: Flow between the latent and the target distributions.\n",
    "    data_match_fn: Function to match samples from the source and the target\n",
    "      distributions. Depending on the data passed in :meth:`__call__`, it has\n",
    "      the following signature:\n",
    "\n",
    "      - ``(src_lin, tgt_lin) -> matching`` - linear matching.\n",
    "      - ``(src_quad, tgt_quad, src_lin, tgt_lin) -> matching`` -\n",
    "        quadratic (fused) GW matching. In the pure GW setting, both ``src_lin``\n",
    "        and ``tgt_lin`` will be set to :obj:`None`.\n",
    "\n",
    "    source_dim: Dimensionality of the source distribution.\n",
    "    target_dim: Dimensionality of the target distribution.\n",
    "    condition_dim: Dimension of the conditions. If :obj:`None`, the underlying\n",
    "      velocity field has no conditions.\n",
    "    time_sampler: Time sampler with a ``(rng, n_samples) -> time`` signature.\n",
    "    latent_noise_fn: Function to sample from the latent distribution in the\n",
    "      target space with a ``(rng, shape) -> noise`` signature.\n",
    "      If :obj:`None`, multivariate normal distribution is used.\n",
    "    latent_match_fn: Function to match samples from the latent distribution\n",
    "      and the samples from the conditional distribution with a\n",
    "      ``(latent, samples) -> matching`` signature. If :obj:`None`, no matching\n",
    "      is performed.\n",
    "    n_samples_per_src: Number of samples drawn from the conditional distribution\n",
    "      per one source sample.\n",
    "    kwargs: Keyword arguments for\n",
    "      :meth:`~ott.neural.networks.velocity_field.VelocityField.create_train_state`.\n",
    "  \"\"\"  # noqa: E501\n",
    "\n",
    "  def __init__(\n",
    "      self,\n",
    "      vf: velocity_field.VelocityField,\n",
    "      flow: dynamics.BaseFlow,\n",
    "      data_match_fn: DataMatchFn,\n",
    "      *,\n",
    "      source_dim: int,\n",
    "      target_dim: int,\n",
    "      condition_dim: Optional[int] = None,\n",
    "      time_sampler: Callable[[jax.Array, int],\n",
    "                             jnp.ndarray] = solver_utils.uniform_sampler,\n",
    "      latent_noise_fn: Optional[Callable[[jax.Array, Tuple[int, ...]],\n",
    "                                         jnp.ndarray]] = None,\n",
    "      latent_match_fn: Optional[Callable[[jnp.ndarray, jnp.ndarray],\n",
    "                                         jnp.ndarray]] = None,\n",
    "      n_samples_per_src: int = 1,\n",
    "      **kwargs: Any,\n",
    "  ):\n",
    "    self.vf = vf\n",
    "    self.flow = flow\n",
    "    self.data_match_fn = data_match_fn\n",
    "    self.time_sampler = time_sampler\n",
    "    if latent_noise_fn is None:\n",
    "      latent_noise_fn = functools.partial(_multivariate_normal, dim=target_dim)\n",
    "    self.latent_noise_fn = latent_noise_fn\n",
    "    self.latent_match_fn = latent_match_fn\n",
    "    self.n_samples_per_src = n_samples_per_src\n",
    "\n",
    "    self.vf_state = self.vf.create_train_state(\n",
    "        input_dim=target_dim,\n",
    "        condition_dim=source_dim + (condition_dim or 0),\n",
    "        **kwargs\n",
    "    )\n",
    "    self.step_fn = self._get_step_fn()\n",
    "\n",
    "  def _get_step_fn(self) -> Callable:\n",
    "\n",
    "    @jax.jit\n",
    "    def step_fn(\n",
    "        rng: jax.Array,\n",
    "        vf_state: train_state.TrainState,\n",
    "        time: jnp.ndarray,\n",
    "        source: jnp.ndarray,\n",
    "        target: jnp.ndarray,\n",
    "        latent: jnp.ndarray,\n",
    "        source_conditions: Optional[jnp.ndarray],\n",
    "    ):\n",
    "\n",
    "      def loss_fn(\n",
    "          params: jnp.ndarray, time: jnp.ndarray, source: jnp.ndarray,\n",
    "          target: jnp.ndarray, latent: jnp.ndarray,\n",
    "          source_conditions: Optional[jnp.ndarray], rng: jax.Array\n",
    "      ) -> jnp.ndarray:\n",
    "        rng_flow, rng_dropout = jax.random.split(rng, 2)\n",
    "        x_t = self.flow.compute_xt(rng_flow, time, latent, target)\n",
    "        if source_conditions is None:\n",
    "          cond = source\n",
    "        else:\n",
    "          cond = jnp.concatenate([source, source_conditions], axis=-1)\n",
    "\n",
    "        v_t = vf_state.apply_fn({\"params\": params},\n",
    "                                time,\n",
    "                                x_t,\n",
    "                                cond,\n",
    "                                rngs={\"dropout\": rng_dropout})\n",
    "        u_t = self.flow.compute_ut(time, latent, target)\n",
    "\n",
    "        return jnp.mean((v_t - u_t) ** 2)\n",
    "\n",
    "      grad_fn = jax.value_and_grad(loss_fn)\n",
    "      loss, grads = grad_fn(\n",
    "          vf_state.params, time, source, target, latent, source_conditions, rng\n",
    "      )\n",
    "\n",
    "      return loss, vf_state.apply_gradients(grads=grads)\n",
    "\n",
    "    return step_fn\n",
    "\n",
    "  def __call__(\n",
    "      self,\n",
    "      loader: Iterable[Dict[str, np.ndarray]],\n",
    "      n_iters: int,\n",
    "      rng: Optional[jax.Array] = None\n",
    "  ) -> Dict[str, List[float]]:\n",
    "    \"\"\"Train the GENOT model.\n",
    "\n",
    "    Args:\n",
    "      loader: Data loader returning a dictionary with possible keys\n",
    "        `src_lin`, `tgt_lin`, `src_quad`, `tgt_quad`, `src_conditions`.\n",
    "      n_iters: Number of iterations to train the model.\n",
    "      rng: Random key for seeding.\n",
    "\n",
    "    Returns:\n",
    "      Training logs.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    rng = utils.default_prng_key(rng)\n",
    "    training_logs = {\"loss\": []}\n",
    "    for batch in loader:\n",
    "      rng = jax.random.split(rng, 5)\n",
    "      rng, rng_resample, rng_noise, rng_time, rng_step_fn = rng\n",
    "\n",
    "      batch = jtu.tree_map(jnp.asarray, batch)\n",
    "      (src, src_cond, tgt), matching_data = prepare_data(batch)\n",
    "\n",
    "      n = src.shape[0]\n",
    "      time = self.time_sampler(rng_time, n * self.n_samples_per_src)\n",
    "      latent = self.latent_noise_fn(rng_noise, (n, self.n_samples_per_src))\n",
    "\n",
    "      tmat = self.data_match_fn(*matching_data)  # (n, m)\n",
    "      src_ixs, tgt_ixs = solver_utils.sample_conditional(  # (n, k), (m, k)\n",
    "          rng_resample,\n",
    "          tmat,\n",
    "          k=self.n_samples_per_src,\n",
    "      )\n",
    "\n",
    "      src, tgt = src[src_ixs], tgt[tgt_ixs]  # (n, k, ...),  # (m, k, ...)\n",
    "      if src_cond is not None:\n",
    "        src_cond = src_cond[src_ixs]\n",
    "\n",
    "      if self.latent_match_fn is not None:\n",
    "        src, src_cond, tgt = self._match_latent(rng, src, src_cond, latent, tgt)\n",
    "\n",
    "      src = src.reshape(-1, *src.shape[2:])  # (n * k, ...)\n",
    "      tgt = tgt.reshape(-1, *tgt.shape[2:])  # (m * k, ...)\n",
    "      latent = latent.reshape(-1, *latent.shape[2:])\n",
    "      if src_cond is not None:\n",
    "        src_cond = src_cond.reshape(-1, *src_cond.shape[2:])\n",
    "\n",
    "      loss, self.vf_state = self.step_fn(\n",
    "          rng_step_fn, self.vf_state, time, src, tgt, latent, src_cond\n",
    "      )\n",
    "\n",
    "      training_logs[\"loss\"].append(float(loss))\n",
    "      if len(training_logs[\"loss\"]) >= n_iters:\n",
    "        break\n",
    "\n",
    "    return training_logs\n",
    "\n",
    "  def _match_latent(\n",
    "      self, rng: jax.Array, src: jnp.ndarray, src_cond: Optional[jnp.ndarray],\n",
    "      latent: jnp.ndarray, tgt: jnp.ndarray\n",
    "  ) -> Tuple[jnp.ndarray, Optional[jnp.ndarray], jnp.ndarray]:\n",
    "\n",
    "    def resample(\n",
    "        rng: jax.Array, src: jnp.ndarray, src_cond: Optional[jnp.ndarray],\n",
    "        tgt: jnp.ndarray, latent: jnp.ndarray\n",
    "    ) -> Tuple[jnp.ndarray, Optional[jnp.ndarray], jnp.ndarray]:\n",
    "      tmat = self.latent_match_fn(latent, tgt)  # (n, k)\n",
    "\n",
    "      src_ixs, tgt_ixs = solver_utils.sample_joint(rng, tmat)  # (n,), (m,)\n",
    "      src, tgt = src[src_ixs], tgt[tgt_ixs]\n",
    "      if src_cond is not None:\n",
    "        src_cond = src_cond[src_ixs]\n",
    "\n",
    "      return src, src_cond, tgt\n",
    "\n",
    "    cond_axis = None if src_cond is None else 1\n",
    "    in_axes, out_axes = (0, 1, cond_axis, 1, 1), (1, cond_axis, 1)\n",
    "    resample_fn = jax.jit(jax.vmap(resample, in_axes, out_axes))\n",
    "\n",
    "    rngs = jax.random.split(rng, self.n_samples_per_src)\n",
    "    return resample_fn(rngs, src, src_cond, tgt, latent)\n",
    "\n",
    "  def transport(\n",
    "      self,\n",
    "      source: jnp.ndarray,\n",
    "      condition: Optional[jnp.ndarray] = None,\n",
    "      t0: float = 0.0,\n",
    "      t1: float = 1.0,\n",
    "      rng: Optional[jax.Array] = None,\n",
    "      **kwargs: Any,\n",
    "  ) -> jnp.ndarray:\n",
    "    \"\"\"Transport data with the learned plan.\n",
    "\n",
    "    This function pushes forward the source distribution to its conditional\n",
    "    distribution by solving the neural ODE.\n",
    "\n",
    "    Args:\n",
    "      source: Data to transport.\n",
    "      condition: Condition of the input data.\n",
    "      t0: Starting time of integration of neural ODE.\n",
    "      t1: End time of integration of neural ODE.\n",
    "      rng: Random generate used to sample from the latent distribution.\n",
    "      kwargs: Keyword arguments for :func:`~diffrax.odesolve`.\n",
    "\n",
    "    Returns:\n",
    "      The push-forward defined by the learned transport plan.\n",
    "    \"\"\"\n",
    "\n",
    "    def vf(t: jnp.ndarray, x: jnp.ndarray, cond: jnp.ndarray) -> jnp.ndarray:\n",
    "      params = self.vf_state.params\n",
    "      return self.vf_state.apply_fn({\"params\": params}, t, x, cond, train=False)\n",
    "\n",
    "    def solve_ode(x: jnp.ndarray, cond: jnp.ndarray) -> jnp.ndarray:\n",
    "      ode_term = diffrax.ODETerm(vf)\n",
    "      sol = diffrax.diffeqsolve(\n",
    "          ode_term,\n",
    "          t0=t0,\n",
    "          t1=t1,\n",
    "          y0=x,\n",
    "          args=cond,\n",
    "          **kwargs,\n",
    "      )\n",
    "      return sol.ys[0]\n",
    "\n",
    "    kwargs.setdefault(\"dt0\", None)\n",
    "    kwargs.setdefault(\"solver\", diffrax.Tsit5())\n",
    "    kwargs.setdefault(\n",
    "        \"stepsize_controller\", diffrax.PIDController(rtol=1e-5, atol=1e-5)\n",
    "    )\n",
    "\n",
    "    rng = utils.default_prng_key(rng)\n",
    "    latent = self.latent_noise_fn(rng, (len(source),))\n",
    "\n",
    "    if condition is not None:\n",
    "      source = jnp.concatenate([source, condition], axis=-1)\n",
    "\n",
    "    return jax.jit(jax.vmap(solve_ode))(latent, source)\n",
    "\n",
    "\n",
    "def _multivariate_normal(\n",
    "    rng: jax.Array,\n",
    "    shape: Tuple[int, ...],\n",
    "    dim: int,\n",
    "    mean: float = 0.0,\n",
    "    cov: float = 1.0\n",
    ") -> jnp.ndarray:\n",
    "  mean = jnp.full(dim, fill_value=mean)\n",
    "  cov = jnp.diag(jnp.full(dim, fill_value=cov))\n",
    "  return jax.random.multivariate_normal(rng, mean=mean, cov=cov, shape=shape)\n",
    "\n",
    "def prepare_data(\n",
    "    batch: Dict[str, jnp.ndarray]\n",
    ") -> Tuple[Tuple[jnp.ndarray, Optional[jnp.ndarray], jnp.ndarray],\n",
    "           Tuple[jnp.ndarray, jnp.ndarray, Optional[jnp.ndarray],\n",
    "                 Optional[jnp.ndarray]]]:\n",
    "  src_lin, src_quad = batch.get(\"src_lin\"), batch.get(\"src_quad\")\n",
    "  tgt_lin, tgt_quad = batch.get(\"tgt_lin\"), batch.get(\"tgt_quad\")\n",
    "\n",
    "  if src_quad is None and tgt_quad is None:  # lin\n",
    "    src, tgt = src_lin, tgt_lin\n",
    "    arrs = src_lin, tgt_lin, None, None\n",
    "  elif src_lin is None and tgt_lin is None:  # quad\n",
    "    src, tgt = src_quad, tgt_quad\n",
    "    arrs = None, None, src_quad, tgt_quad\n",
    "  elif all(\n",
    "      arr is not None for arr in (src_lin, tgt_lin, src_quad, tgt_quad)\n",
    "  ):  # fused quad\n",
    "    src = jnp.concatenate([src_lin, src_quad], axis=1)\n",
    "    tgt = jnp.concatenate([tgt_lin, tgt_quad], axis=1)\n",
    "    arrs = src_lin, tgt_lin, src_quad, tgt_quad\n",
    "  else:\n",
    "    raise RuntimeError(\"Cannot infer OT problem type from data.\")\n",
    "\n",
    "  return (src, batch.get(\"src_condition\"), tgt), arrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf3f0ef-e424-4872-8bd4-f7d6abdd1568",
   "metadata": {},
   "source": [
    "# Different solve functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5836e823-633b-41eb-a7ef-ad1ecd55bb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def solve_gw(epsilon: float, xx: jax.Array, yy: jax.Array, cost_fn : Any):\n",
    "    ot_solver = gromov_wasserstein.GromovWasserstein(epsilon=epsilon)\n",
    "    geom_xx = pointcloud.PointCloud(\n",
    "        x=xx, y=xx, cost_fn=cost_fn, scale_cost=\"mean\"\n",
    "    )\n",
    "    geom_yy = pointcloud.PointCloud(\n",
    "        x=yy, y=yy, cost_fn=cost_fn, scale_cost=\"mean\"\n",
    "    )\n",
    "    geom_xy = None\n",
    "    prob = quadratic_problem.QuadraticProblem(\n",
    "        geom_xx, geom_yy, geom_xy,\n",
    "    )\n",
    "    return ot_solver(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2303fb3b-5b12-4361-82cc-654784523059",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def solve_fgw(epsilon: float, xx: jax.Array, yy: jax.Array, xy_x: jax.Array, xy_y: jax.Array, fused_penalty: float, cost_fn : str):\n",
    "    ot_solver = gromov_wasserstein.GromovWasserstein(epsilon=epsilon)\n",
    "    geom_xx = pointcloud.PointCloud(\n",
    "        x=xx, y=xx, cost_fn=cost_fn, scale_cost=\"mean\"\n",
    "    )\n",
    "    geom_yy = pointcloud.PointCloud(\n",
    "        x=yy, y=yy, cost_fn=cost_fn, scale_cost=\"mean\"\n",
    "    )\n",
    "    geom_xy = pointcloud.PointCloud(\n",
    "                    x=xy_x, y=xy_y, cost_fn=cost_fn, scale_cost=\"mean\"\n",
    "                )\n",
    "    prob = quadratic_problem.QuadraticProblem(\n",
    "        geom_xx, geom_yy, geom_xy, fused_penalty=fused_penalty,\n",
    "    )\n",
    "    return ot_solver(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa1ef302-9967-43a8-9585-5afc9ea6ce55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nearest_neighbors(\n",
    "    X: jnp.ndarray, Y: Optional[jnp.ndarray], k: int = 30  # type: ignore[name-defined]\n",
    ") -> Tuple[jnp.ndarray, jnp.ndarray]:  # type: ignore[name-defined]\n",
    "    concat = X if Y is None else jnp.concatenate((X, Y), axis=0) \n",
    "    pairwise_euclidean_distances = pointcloud.PointCloud(concat, concat).cost_matrix\n",
    "    distances, indices = jax.lax.approx_min_k(\n",
    "        pairwise_euclidean_distances, k=k, recall_target=0.95, aggregate_to_topk=True\n",
    "    )\n",
    "    connectivities = jnp.multiply(jnp.exp(-distances),  (distances>0))\n",
    "    return connectivities/jnp.sum(connectivities), indices\n",
    "\n",
    "\n",
    "def create_cost_matrix_quad(X: jnp.array, k_neighbors: int, **kwargs: Any) -> jnp.array:\n",
    "    distances, indices = get_nearest_neighbors(X, None, k_neighbors)\n",
    "    a = jnp.zeros((len(X), len(X)))\n",
    "    adj_matrix = a.at[\n",
    "        jnp.repeat(jnp.arange(len(X)), repeats=k_neighbors).flatten(), indices.flatten()\n",
    "    ].set(distances.flatten())\n",
    "    return graph.Graph.from_graph(adj_matrix, normalize=kwargs.pop(\"normalize\", True), **kwargs).cost_matrix\n",
    "\n",
    "@jax.jit\n",
    "def solve_gw_geodesic(epsilon: float, xx: jax.Array, yy: jax.Array, k_neighbors=1024):\n",
    "    ot_solver = gromov_wasserstein.GromovWasserstein(epsilon=epsilon)\n",
    "    cm_xx = create_cost_matrix_quad(xx, k_neighbors)\n",
    "    cm_yy = create_cost_matrix_quad(yy, k_neighbors)\n",
    "    geom_xx = geometry.Geometry(cost_matrix=cm_xx, epsilon=epsilon, scale_cost=\"mean\")\n",
    "    geom_yy = geometry.Geometry(cost_matrix=cm_yy, epsilon=epsilon, scale_cost=\"mean\")\n",
    "    geom_xy = None\n",
    "    prob = quadratic_problem.QuadraticProblem(\n",
    "        geom_xx, geom_yy, geom_xy,\n",
    "    )\n",
    "    \n",
    "    return ot_solver(prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8f9aa5b-5db3-4ce2-9497-a699b063aae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def get_quad_initializer(push_forward: jnp.ndarray, target: jnp.ndarray):\n",
    "    pc = pointcloud.PointCloud(push_forward, target)\n",
    "    geom = geometry.Geometry(pc.cost_matrix, epsilon=1e-2)\n",
    "    lp = linear_problem.LinearProblem(geom, a=jnp.ones(n) / n, b=jnp.ones(n) / n)\n",
    "    return lp\n",
    "    \n",
    "def solve_gw_with_init(epsilon: float, xx: jax.Array, yy: jax.Array, cost_fn : Any, model: GENOT):\n",
    "    push_forward = model.transport(xx)\n",
    "    initializer = get_quad_initializer(push_forward, yy)\n",
    "    ot_solver = gromov_wasserstein.GromovWasserstein(epsilon=epsilon)\n",
    "    geom_xx = pointcloud.PointCloud(\n",
    "        x=xx, y=xx, cost_fn=cost_fn, scale_cost=\"mean\"\n",
    "    )\n",
    "    geom_yy = pointcloud.PointCloud(\n",
    "        x=yy, y=yy, cost_fn=cost_fn, scale_cost=\"mean\"\n",
    "    )\n",
    "    prob = quadratic_problem.QuadraticProblem(\n",
    "        geom_xx, geom_yy, \n",
    "    )\n",
    "    return ot_solver(prob, init=initializer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a85a39-9023-478a-8121-2006162009b6",
   "metadata": {},
   "source": [
    "# Set hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08e2c5a2-9716-4293-92d6-23a43a852783",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon=0.01\n",
    "n = 1024 # batch size\n",
    "N_POINTS = 10\n",
    "N_DRAWS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea5287c-8b12-4238-a507-2a6fd6b423a0",
   "metadata": {},
   "source": [
    "# Generate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0359895-3389-4dff-8b30-5120066268ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_atac = datasets.bone_marrow(rna=False)\n",
    "adata_rna = datasets.bone_marrow(rna=True)\n",
    "adata_atac.obsm[\"ATAC_lsi_l2_norm\"] = pp.normalize(\n",
    "    adata_atac.obsm[\"ATAC_lsi_red\"], norm=\"l2\"\n",
    ")\n",
    "x_quad = sc.pp.pca(adata_atac.obsm[\"ATAC_lsi_l2_norm\"], n_comps=20)\n",
    "y_quad = sc.pp.pca(adata_rna.obsm['GEX_X_pca'], n_comps=20)\n",
    "\n",
    "x_lin_tmp = adata_atac.obsm['geneactivity_scvi']\n",
    "y_lin_tmp = adata_rna.obsm['geneactivity_scvi']\n",
    "\n",
    "xy = sc.pp.pca(np.concatenate((x_lin_tmp, y_lin_tmp), axis=0), n_comps=10)\n",
    "x_lin = xy[:len(x_lin_tmp)]\n",
    "y_lin = xy[len(x_lin_tmp):]\n",
    "\n",
    "x_all = np.concatenate((x_lin, x_quad) , axis=1)\n",
    "y_all = np.concatenate((y_lin, y_quad), axis=1)\n",
    "\n",
    "DIM_FUSED = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bb8e38-85df-4969-9677-fca895a72eae",
   "metadata": {},
   "source": [
    "# GW with graph cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af31641b-675a-4c31-9081-81decff2be3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                            | 0/10 [00:00<?, ?it/s]2024-08-04 19:24:29.258312: W external/xla/xla/service/gpu/nvptx_compiler.cc:836] The NVIDIA driver's CUDA version is 12.4 which is older than the PTX compiler version (12.6.20). Because the driver is older than the PTX compiler version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [02:10<00:00, 13.08s/it]\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng(12345)\n",
    "\n",
    "epsilon_graph = epsilon\n",
    "vars_gw_graph = [None] * N_POINTS\n",
    "for it in tqdm(range(N_POINTS)):\n",
    "    minibatch_match = [None] * N_DRAWS\n",
    "    x_fixed = rng.choice(x_all, size=(1,))\n",
    "    for i in range(N_DRAWS):\n",
    "        x = rng.choice(x_all, size=(n-1,))\n",
    "        x = np.concatenate((x_fixed, x), axis=0)\n",
    "        y = rng.choice(y_all, size=(n,))\n",
    "        xx = x[:,DIM_FUSED:]\n",
    "        yy = y[:,DIM_FUSED:]\n",
    "        out = solve_gw_geodesic(epsilon_graph, xx, yy)\n",
    "        likelihood = np.asarray(out.matrix[0]).astype('float64')\n",
    "        minibatch_match[i] = rng.choice(yy, p=likelihood/np.sum(likelihood), shuffle=False)\n",
    "    vars_gw_graph[it] = np.var(minibatch_match, axis=0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47ef8841-9527-4604-ac44-90f09ea71a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{dataset}_graph_{epsilon_graph}.npy', 'wb') as f:\n",
    "    np.save(f, vars_gw_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "133a5759-cf03-425e-86cc-544c287bfcfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [07:38<00:00, 45.80s/it]\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng(12345)\n",
    "\n",
    "epsilon_graph = 1e-4\n",
    "vars_gw_graph = [None] * N_POINTS\n",
    "for it in tqdm(range(N_POINTS)):\n",
    "    minibatch_match = [None] * N_DRAWS\n",
    "    x_fixed = rng.choice(x, size=(1,))\n",
    "    for i in range(N_DRAWS):\n",
    "        x = rng.choice(x, size=(n-1,))\n",
    "        x = np.concatenate((x_fixed, x), axis=0)\n",
    "        y = rng.choice(y, size=(n,))\n",
    "        xx = x[:,DIM_FUSED:]\n",
    "        yy = y[:,DIM_FUSED:]\n",
    "        out = solve_gw_geodesic(epsilon_graph, xx, yy)\n",
    "        likelihood = np.asarray(out.matrix[0]).astype('float64')\n",
    "        minibatch_match[i] = rng.choice(yy, p=likelihood/np.sum(likelihood), shuffle=False)\n",
    "    vars_gw_graph[it] = np.var(minibatch_match, axis=0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bae2cd9c-72d6-4cd0-bbae-7d386333e031",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{dataset}_graph_{epsilon_graph}.npy', 'wb') as f:\n",
    "    np.save(f, vars_gw_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5e0c5c5-b99a-4945-b79f-41b712119791",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_g1 = np.load(f\"{dataset}_graph_0.01.npy\")\n",
    "res_g2 = np.load(f\"{dataset}_graph_0.0001.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f3e96bd-6846-4e0e-93fe-7e9afa5ba18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_g1_mean = np.mean(res_g1, axis=0)\n",
    "res_g2_mean = np.mean(res_g2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5251e5b-21dd-4b75-93d1-db8a19b707e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([61.97741  , 21.803251 , 11.612076 ,  8.697136 ,  5.3289843,\n",
       "        2.9707897,  2.5559046,  1.9997063,  1.931324 ,  1.972929 ,\n",
       "        1.5381061,  1.4914898,  1.4200451,  1.3044698,  1.1463658,\n",
       "        1.3592931,  0.9774721,  0.8938856,  1.0035172,  0.8482791],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_g1_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2458ae1a-bc50-4e21-bed6-7f58fff22d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17.576633  , 10.672904  ,  4.5450497 , 22.352678  ,  1.7365946 ,\n",
       "        1.2827942 ,  1.5664084 ,  0.58604085,  0.66009676,  0.70645356,\n",
       "        0.9827353 ,  0.54497397,  0.64035094,  0.5654494 ,  0.69637895,\n",
       "        0.39773476,  0.57704294,  1.1055791 ,  0.2774175 ,  0.5372273 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_g2_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d3263ae-2618-4b0f-a098-1a483753aef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.641622"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(res_g1_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cebdd644-12a5-464e-bf10-684f81ff7287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.4005268"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(res_g2_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53c5398-950f-4246-bbd1-e1687fb63b7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "entot_neurips",
   "language": "python",
   "name": "entot_neurips"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
